---
title: "Étude de cas - GLM et valeurs manquantes"
author: "Romane Lacoste-Badie, Margaux Touzé et Camille Loisel"
date: "02/03/2022"
header-includes:
  - \DeclareUnicodeCharacter{0301}{/}
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lmtest)
library(stats)
library(car)
library(MASS)
library(ResourceSelection)
library(ROCR)
library(dplyr)
library(knitr)
library(gridExtra)
library(ggplot2)
```

```{=tex}
\newpage
\renewcommand{\contentsname}{Sommaire}
\tableofcontents
```
\newpage

Note à nous meme à dégager plus tard : j'ai rajouté le declareunicodecharacter tout en haut sinon ca voulait pas sortir un pdf.

# I. Modèles linéaires généralisés (GLM) avec R

#### Importation des données

```{r}
#mites<-read.csv("/Users/margauxtouze/Desktop/FAC/M2/S2/Étude de cas/Data/mites.csv")
mites <- read.csv("mites.csv")
```

\newpage

## Introduction

L'objectif de cette première partie est d'étudier le jeu de données sur les mites Oribatid mis à disposition par P. Legendre et D. Borcard et décrit dans leur article *Borcard et al. 1994*. Tout particulièrement, nous essaierons de construire différents modèles linéaires simples puis généralisés pour décrire trois des variables de ce jeu de données.

Pour leur étude, Legendre et Borcard ont,choisit une zone située à Saint-Hippolyte, Canada, qu'ils ont divisé en 70 "coeurs". Pour chaque coeur, ils ont récupéré des données environnementales et sur la faune. Le jeu de données que l'on étudie est donc constitué de 70 observations qui correspondent aux coeurs, et de 9 variables décrites ci-dessous.

```{r}
str(mites)
```

-   **Galumna** (entier) : nombre de mites *Galumna sp*.

-   **pa** (0 ou 1) : présence (1) ou absence (0) de mites Galumna sp.

-   **totalabund** (entier) : nombre total de mites

-   **prop** (réel entre 0 et 1) : proportion de mites Galumna sp.

-   **SubsDens** (réel) : densité du substrat en $g.L^{-1}$ de matière sèche non comprimée

-   **WatrCont** (réel) : contenu en eau du substrat en $g.L^{-1}$

-   **Substrate** (facteur) : type de substrat, facteur à 7 modalités

-   **Shrub** (facteur) : buissons, facteur à trois modalités

-   **Topo** (facteur) : microtopographie, facteur à 2 modalités Comme décrit ci-dessus, certaines variables sont des facteurs, mais le logiciel R ne les interprète pas comme cela naturellement. Nous allons donc les transformer en facteurs manuellement.

```{r}
mites$pa <- as.factor(mites$pa)
mites$Substrate <- as.factor(mites$Substrate)
mites$Shrub <- as.factor(mites$Shrub)
mites$Topo <- as.factor(mites$Topo)
```

Nous allons maintenant représenter ces données afin de mieux les appréhender.\
Commençons par les variables que l'on va chercher à expliquer par la suite : Galumna, pa et prop.

```{r}
ggplot(data = mites) + geom_bar(mapping = aes(Galumna), fill='darkred') +ylab("Nombre de coeurs")+xlab("Nombre de Galumna")
```

On remarque que plus de la moitié des coeurs étudiés ne contiennent pas de mites Galumna. La valeur maximale de Galumna contenue dans un coeur est 8.

```{r}
ggplot(data = mites) + geom_bar(mapping = aes(pa), fill='darkred') +ylab("Nombre de coeurs")+xlab("Absence ou Présence de Galumna")
```

On voit ci-dessus plus précisément que 45 coeurs ne contiennent pas de Galumna et 25 coeurs en contiennent.

```{r}
ggplot(data=mites) + geom_histogram(aes(prop), fill="darkred") + ylab("Nombre de coeurs")+xlab("Proportion de Galumna")
```

Naturellement, on remarque que 45 coeurs ont une proportion de Galumna de 0%. Pour les autres coeurs, la proportion varie entre 0 et 0.06%.

Passons maintenant aux variables explicatives.

```{r}
ggplot(data=mites) + geom_histogram(aes(SubsDens), fill="darkred", binwidth = 5) + ylab("Nombre de coeurs")+xlab("SubsDens") 
```

```{r}
ggplot(data=mites) + geom_histogram(aes(WatrCont), fill="darkred", binwidth = 40) + ylab("Nombre de coeurs")+xlab("Watrcont") 
```

Nous pouvons observer la distribution des variables quantitatives SubsDens et WatrCont. Cependant, ces variables étant déterministes, on ne fait pas d'hypothèse de normalité. Donc nous n'avons pas besoin de "vérifier" qu'elles suivent une loi normale, ni d'effectuer des transformations pour que cela soit le cas.

```{r}
ggplot(data = mites) + geom_bar(mapping = aes(Substrate), fill="darkred") +ylab("Nombre de coeurs")+xlab("Substrate")
```

Les deux types de substrat majoritaires sont "Interface" et "Sphagn1", qui sont chacun le substrat d'environ 25 coeurs sur les 70 totaux.

```{r}
ggplot(data = mites) + geom_bar(mapping = aes(Shrub), fill="darkred") +ylab("Nombre de coeurs")+xlab("Shrub")
```

La variable `Shrub` représente les buissons du coeur. On voit qu'un peu moins d'une vingtaine de coeurs ne contient pas de buisson. Puis environ 25 coeurs contiennnt beaucoup de buissons et peu de buissons.

```{r}
ggplot(data = mites) + geom_bar(mapping = aes(Topo), fill="darkred") +ylab("Nombre de coeurs")+xlab("Topo")
```

Finalement, on voit qu'environ 45 coeurs ont une topographie de type "Blanket", les autres ont une topographie de type "Hummock".

Ce premier coup d'oeil aux données nous a permis de remarquer quelque chose d'important : plus de la moitié des coeurs ne contiennent pas de Galumna. Cela siginifie, pour ceux-ci, que la proportion de Galumna est nulle, que la variable Galumna est égale à 0 et que la variable occurence de Galumna est également égale à 0. Il s'agit de garder cela à l'esprit pour la future construction de nos modèles.

pour LM : chercher à valider les hypothèses, ca marche pas, faire des transformations (Box Cox), réessayer de valider les hyp Si ca marche on dit quon pourrait sarreter la mais on cherche a aller plus loin Si ca marche PAS on cherche un autre modele : GLM (si abundance marche, possibilité de faire +1 pour éviter les valeurs=0)

\newpage

## 1. LM Gaussien

Dans un premier temps, nous allons essayer d'ajuster un modèle linéaire gaussien pour chaque variable réponse que l'on cherche à expliquer : `Galumna`, `prop`, `pa`. Mais un tel modèle doit vérifier plusieurs hypothèses. Le premier travail consiste donc à regarder si ces hypothèses sont vérifiées. Rappelons les hypothèses du modèle linéaire gaussien :

-   sur la forme du modèle :\
    (H1) **linéarité** du modèle\

-   sur les erreurs $\epsilon_i$ qui sont :\
    (H2) **centrées** : $\mathbb{E}(\epsilon_i)=0, \forall i=1,..n$\, cette condition est toujours vérifiée par les moindres carrés ordinaires (MCO), technique de résolution de la régression linéaire
    (H3) **homoscédastiques** : $\mathbb{V}(\epsilon_i)=\sigma^2, \forall i$\
    (H4) **non-autocorrélées** : $cor(\epsilon_i, \epsilon_{i}^{'})=0, \forall i\neq i'$\
    (H5) **normales** : $\epsilon_i \sim N(0, \sigma^2)$\

-   sur les variables explicatives $X_1,...,X_p$ qui sont :\
    (H6) **non aléatoires** : la théorie se généralise facilement pour les variables aléatoires\
    (H7) **non multicolinéaires** : les variables $X_1,...,X_p$ sont linéairement indépendantes, ce qui garantit l'unicité de l'estimateur MCO.

Pour chaque modèle expliquant `Galumna`, `prop` et `pa`, nous regarderons si toutes ces hypothèses sont vérifiées, sauf la **2** et la **6** qui sont toujours vérifiées.

L'utilisation d'un modèle linéaire nous impose de traiter la variable pa comme une valeur réelle et non comme un facteur. Nous allons donc la retransformer manuellement.

```{r}
mites$pa <- as.integer(mites$pa)
```

### (H1) Linéarité du modèle

Nous allons observer la linéarité du modèle dans un premier temps par représentation graphique. Nous représenterons chaque variable à expliquer en fonction des variables `WatrCont` et `SubsDens` qui sont les deux seules variables quantitatives explicatives.

**Variable réponse Galumna**

```{r}
p1 <- ggplot(data=mites, aes(x=SubsDens, y=Galumna)) + geom_point() + geom_smooth(method="lm", formula = y~x, aes(color="lm(Galumna~SubsDens)"), se=F) +scale_colour_manual(name="Regression model", breaks=c("lm(Galumna~SubsDens)"), values=c("darkred")) + theme(legend.position = "top")
p2 <- ggplot(data=mites, aes(x=WatrCont, y=Galumna)) + geom_point() + geom_smooth(method="lm", formula = y~x, aes(color="lm(Galumna~WatrCont)"), se=F) +scale_colour_manual(name="Regression model", breaks=c("lm(Galumna~WatrCont)"), values=c("darkred")) + theme(legend.position = "top")
p2
grid.arrange(p1,p2, nrow=1)
```

On ne voit pas un lien linéaire évident entre Galumna et SubsDens, ni entre Galumna et WatrCont. On voit que la quantité importante de points sur l'axe des abscisses (pour lesquels Galumna=0) semble beaucoup impacter la droite de régression.

**Variable réponse pa**

```{r}
p1 <- ggplot(data=mites, aes(x=SubsDens, y=pa)) + geom_point() + geom_smooth(method="lm", formula = y~x, aes(color="lm(pa~SubsDens)"), se=F) +scale_colour_manual(name="Regression model", breaks=c("lm(pa~SubsDens)"), values=c("darkred")) + theme(legend.position = "top")
p2 <- ggplot(data=mites, aes(x=WatrCont, y=pa)) + geom_point() + geom_smooth(method="lm", formula = y~x, aes(color="lm(pa~WatrCont)"), se=F) +scale_colour_manual(name="Regression model", breaks=c("lm(pa~WatrCont)"), values=c("darkred")) + theme(legend.position = "top")
p2
grid.arrange(p1,p2, nrow=1)
```

On ne voit pas non plus un lien linéaire entre la variable pa et les variables explicatives. De plus, comme c'est une variable binaire, il semblerait plus naturel de penser à une régression logistique qu'à une régression linéaire.

**Variable réponse prop**

```{r}
p1 <- ggplot(data=mites, aes(x=SubsDens, y=prop)) + geom_point() + geom_smooth(method="lm", formula = y~x, aes(color="lm(prop~SubsDens)"), se=F) +scale_colour_manual(name="Regression model", breaks=c("lm(prop~SubsDens)"), values=c("darkred")) + theme(legend.position = "top")
p2 <- ggplot(data=mites, aes(x=WatrCont, y=prop)) + geom_point() + geom_smooth(method="lm", formula = y~x, aes(color="lm(prop~WatrCont)"), se=F) +scale_colour_manual(name="Regression model", breaks=c("lm(prop~WatrCont)"), values=c("darkred")) + theme(legend.position = "top")
p2
grid.arrange(p1,p2, nrow=1)
```

On fait le même constat pour la variable prop, il ne semble pas y avoir un lien linéaire particulier et la présence de beaucoup de points sur l'axe des abscisses semble influencer fortement la droite de régression.

Pour pousser notre analyse plus loin, nous allons effectuer un test de Harvey-Collier sur les modèles qui expliquent nos variables réponses par les deux variables explicatives quantitatives (SubsDens et WatrCont). Le test de Harvey-Collier consiste à faire un test de Student sur les résidus récursifs. Si la réelle relation entre les variables n'est pas linéaire mais convexe ou concave, la moyenne des résidus récursifs devrait être significativement différente de 0.

```{r}
kable(data.frame("p-value Harvey-Collier Test" =
                   c(harvtest(lm(Galumna~WatrCont+SubsDens, data=mites))$p.value,
                     harvtest(lm(pa~WatrCont+SubsDens, data=mites))$p.value,
                     harvtest(lm(prop~WatrCont+SubsDens, data=mites))$p.value),
                    row.names=c("Galumna~WatrCont+SubsDens",
                                  "pa~WatrCont+SubsDens",
                                  "prop~WatrCont+SubsDens")))
```

Au seuil de 5%, on peut conclure que :

-   la relation entre la variable pa et les variables WatrCont et SubsDens n'est pas linéaire

-   la relation entre la variable Galumna et les variables WatrCont et SubsDens est linéaire

-   la relation entre la variable prop et les variables WatrCont et SubsDens est linéaire

À ce stade de l'analyse, on peut déjà conclure qu'il ne sera pas possible d'ajuster un modèle linéaire sur le variable `prop` car l'hypothèse de linéarité n'est pas vérifiée.

### (H3) Erreurs $\epsilon_i$ homoscédastiques

Pour la suite de la vérification des hypothèses, on ajuste un modèle complet sur chacune de nos variables réponses (i.e. un modèle qui fait intervenir toutes les variables explicatives à notre disposition).
```{r}
lm.tot.g<-lm(Galumna~.-pa-prop-totalabund, data=mites)
lm.tot.pa<-lm(pa~.-Galumna-prop-totalabund, data=mites)
lm.tot.prop<-lm(prop~.-pa-Galumna-totalabund, data=mites)
```

```{r}
par(mfrow=c(2,2))
plot(lm.tot.g, which = 3)
plot(lm.tot.pa, which = 3)
plot(lm.tot.prop, which = 3)
```
Ajouter les légendes !

Le type de graphique représenté ci-dessus est utiliser pour évaluer l'homoscédasticité des résidus. Si leur variance est bein constante, alors la courbe rouge doit former une ligne à peu près horizontale. On voit que cette hypothèse est plutôt bien respectée pour les modèles expliquant les variables Galumna et prop. Par contre, l'hypothèse n'est manifestement pas vérifiée pour le modèle expliquant la variable pa.

La vérification de cette hypothèse peut également se faire par un test de Breusch-Pagan pour lequel on a $H_0$ : le bruit est homoscédastique, i.e. $\sigma_i^2=\sigma^2$ pour tout $i$.

```{r}
kable(data.frame("p-value Bruesch-Pagan Test" =
                   c(bptest(lm.tot.g)$p.value,
                     bptest(lm.tot.pa)$p.value,
                     bptest(lm.tot.prop)$p.value),
                    row.names=c("Galumna~WatrCont+SubsDens",
                                  "pa~WatrCont+SubsDens",
                                  "prop~WatrCont+SubsDens")))
```
Ce test confirme notre conclusion d'après les graphiques : on rejette l'hypothèse d'homoscédasticité des résidus pour le modèle expliquant pa, mais on l'accepte pour les deux autres modèles.

### (H4) : Non autocorrélation des erreurs -\> test de Durbin-Watson : H0 : Les résidus sont non correles

```{r}
dwtest(lm.tot.g)
dwtest(lm.tot.pa)
dwtest(lm.tot.prop)
```

On rejete pour pa et prop

### (H5) : Normalité des erreurs

```{r}
plot(lm.tot.g, which = 2)
plot(lm.tot.pa, which = 2)
plot(lm.tot.prop, which = 2)
```

-   Normal Q-Q : Ce plot ets utilisé pour determiné sir les residus du model sont distribués suivant une loi normale (les points doivent suivre la ligne pour repondre à cette hypothese) (H5)

Si la rpz est (a peu pres) une droite, l'hyp de normalité est accepté

-\> Test de Shapiro-Wilks : H0 : normalité

```{r}
shapiro.test(lm.tot.g$residuals)
shapiro.test(lm.tot.pa$residuals)
shapiro.test(lm.tot.prop$residuals)
```

Rejete H0 pour les trois

(H7) : Non multicolinéarité des variables explicatives

```{r}
plot(mites$SubsDens, mites$WatrCont)
boxplot(mites$SubsDens~as.factor(mites$Substrate))

barplot(table(mites$Substrate, mites$Topo), legend.text=T)
```

Faible tendance linéaire présente Faire boxplot pour quanti-quali barplot : On observe que les

```{r}
vif(lm.tot.g)
vif(lm.tot.pa)
vif(lm.tot.prop)
```

Toujours superieur a 1, \>5 trop eleve donc pb de multicolineralité

CONCLUSION DU I) : Hypotheses du LM pas veirifées donc on ne peux pas prendre un modele linéaire

Transformation Logit :

```{r}
logitTransform <- function(p) { log(p/(1-p)) }
prop.logit <- logitTransform(mites$prop)
plot(mites$prop, prop.logit)
#lm.prop.logit <- lm(prop.logit~.-pa-prop-totalabund-Galumna, data =mites)
```

Probleme car Lise ne test pas ses enoncés avant de nous les donner -\> demander à Juju 0 dans prop, donc probleme avec le logit car logit(0) non defini

Tranformation arcsin :

```{r}
asinTransform <- function(p) { asin(sqrt(p)) }
prop.asin <- asinTransform(mites$prop)
plot(mites$prop, prop.asin)
lm.prop.asin <- lm(prop.asin~.-pa-prop-totalabund-Galumna, data =mites)
```

-\> Re vérifier toutes les hypotheses comme dans le I)

(H3) : Homoscédasticité : -\> Plot des résidus : "Scale-Location"

```{r}
plot(lm.prop.asin, which =3)
bptest(lm.prop.asin)
```

Pas tres concluant pour amélirorer les problemes de variance, car deja bien avant la transformation.

Transformation de Box-Cox :

```{r}
boxcox 
```

\newpage

## 2. GLM Régression logistique binaire sur la variable réponse Occurrence (pa)

**Objectif** : expliquer l'occurence `pa`, déterminer le meilleur modèle, interpréter les coefficients, puis évaluer l'ajustement de ce modèle et son pouvoir prédictif.

#### 1. Recherche du meilleur modèle

-   **Méthode "à la main"**

Pour débuter, on construit le modèle complet (avec toutes les variables explicatives) pour déterminer lesquelles sont significatives :

```{r}
glm.tot.pa <- glm(pa~WatrCont + SubsDens + Topo + Shrub + Substrate, data=mites, family = "binomial")
summary(glm.tot.pa)
```

D'après cette sortie, les variables significatives semblent être WatrCont, SubsDens et Topo.

On peut alors tester un modèle uniquement avec celles-ci :

```{r}
glm.best.pa <- glm(pa~WatrCont + SubsDens + Topo, data=mites, family = "binomial")
summary(glm.best.pa)
```

Ce modèle semble mieux car les variables sont toutes vraiment significatives.

Afin de s'assurer de la significativité du retrait des autres variables, nous pouvons réaliser un test de déviance. **DEFINIR**

```{r}
anova(glm.best.pa, glm.tot.pa, test = 'Chisq')
```

La grande p-value nous indique que les variables présentes dans le plus grand modèle mais pas dans les plus petit ne sont pas significatives. Avant de confirmer le choix de ce modèle, regardons les valeurs du critère BIC (critère explicatif) pour chacun des deux modèles.

```{r}
kable(data.frame(BIC(glm.best.pa),BIC(glm.tot.pa)), col.names = c("Petit modèle", "Grand modèle"), caption = "BIC")
```

En accord avec les résultats précédents, le critère BIC est inférieur pour le petit modèle. Cela confirme notre choix de garder uniquement les variables WatrCont, SubsDens et Topo.

Nous pouvons comparer ce modèle obtenu avec celui déterminé par une sélection automatique.

-   **Méthode de sélection automatique**

Nous effectuons une sélection stepwise descendante, toujours avec le critère BIC. Celle-ci part du plus gros modèle et tente d'enlever les varaibles les moins significtives afin de retrouver le meilleur modèle.

```{r}
n <- nrow(mites)
glm.tot.pa.step <- step(glm.tot.pa, direction = "backward", k = log(n))
glm.tot.pa.step$formula
```

La sélection automatique retient également le modèle contenant les variables WatrCont, SubsDens et Topo car c'est celui pour lequel le BIC est le plus faible.

Par conséquent, nous retenons le modèle suivant pour la suite :

$$logit(\hat{Pa})= - 0.583 - 0.022*WatrCont +0.173*SubsDens + 2.738*TopoHummock$$

#### 2. Interprétation des coefficients

La sortie de notre modèle indique que le contenu en eau, la densité du substrat et la topographie sont associés significativement à l'occurrence de mites. Cependant, on peut également interpréter les coefficients de la pente grâce aux odds-ratio. Ce dernier est équivalent à $\exp(\beta_j)$ pour la variable $j$.

```{r}
exp(glm.best.pa$coefficients)
```

Grâce à ces coefficients, nous pouvons déterminer le pourcentage de probabilité de la présence de mites, lorsque que l'on augmente l'une des variables. En effet, pour chaque augmentation d'une unité du contenu en eau (WatrCont), nous avons $2.2$% ($0.978*100 - 100$) de risque en moins d'avoir une présence de mites, tandis ce que pour une unité de densité du substrat (SubsDens) en plus, le risque est plus élevé de $18$%. Enfin, lorsque de la topographie est de type Hummock, il y a énroméménet de probabilité d'avoir des mites, pusique celle-ci augmente de plus de $1400$%.

#### 3. Validation du modèle

Afin de valider notre modèle, nous allons à présent évaluer son ajustement, ainsi que ses pouvoirs explicatifs et de classfication.

-   **Evaluation de l'ajustement du modèle**

    -   Effet levier

    Dans un premier temps, nous pouvons nous intéresser aux points leviers, c'est à dire les points qui influencent fortement sur leur propre estimation.

    ```{r}
    p <- length(glm.best.pa$coefficients)
    n <- nrow(mites)
    plot(influence(glm.best.pa)$hat, type="h", ylab="h_ii")
    abline(h=c(2*p/n, 3*p/n), col=2)
    ```

    On remarque sur le graphique précédent que quatre observations peuvent être considérées comme points leviers. Une connaissance plus approfondie du jeu de données nous permettrait de comprendre plus en détails ces résultats.

    -   Points influents

    Regardons ensuite les points influents sur le modèle. Ce sont des points importants car leur présence joue beaucoup sur l'estimation des coefficients. Pour les déterminer, on peut représenter leur distance de Cook, c'est à dire la distance entre le vecteur des coefficients estimés avec toutes les observations et celui estimé avec toutes les observations sauf une.

    ```{r}
    plot(cooks.distance(glm.best.pa), type="h", ylab="Distance de Cook")
    ```

    Sur le graphique obtenu, on remarque notamment l'observation 15 qui a une distance de Cook nettement supérieure aux autres. Cela signifie que c'est un point influent. Là encore, il serait necessaire de connaître plus en détails notre jeu de données pour pouvoir l'expliquer et notammant déterminer si c'est un point levier, un point abberrant ou les deux. Nous pouvons tout de même remarquer qu'il figurait déja dans les points à effet levier relevés précédemment.

    -   Test de Pearson

    Afin de tester la qualité de l'ajustement de notre modèle, on peut utiliser le test de Pearson basé sur les résidus de Pearson. **DÉFINIR**

    ```{r}
    res <- sum(residuals(glm.best.pa, type = "pearson")^2)
    ddl <- df.residual(glm.best.pa)
    pvalue <- 1 - pchisq(res,ddl)
    pvalue
    ```

    La p-value étant très grande, on admet que le modèle est très bien adapté aux données. On peut tout de même visualiser ces résidus de Pearson.

    ```{r}
    res2 <- residuals(glm.best.pa, type="pearson")
    plot(res2, ylab="Residuals")
    abline(h=c(-2,2), col=2)
    ```

    Nous remarquons deux individus ayant des résidus élevés. Une nouvelle fois, nous retrouvons l'individu 15. Il serait peut-être judicieux de l'enlever pour la suite. Cependant, le jeu de données n'étant pas très grand, nous décidons de le conserver afin de ne pas le réduire davantage.

    -   Test d'Hosmer-Lemeshow

    Par ailleurs, on peut également effectuer un test d'Hosmer-Lemeshow pour évaluer la pertinence du modèle. **DÉFINIR**

    ```{r}
    hoslem.test(mites$pa, fitted(glm.best.pa))
    ```

    De même, la très grande p-value nous indique que le modèle est bien adapté aux données.

    Avant de valider définitivement le choix de ce modèle, il faut évaluer son pouvoir explicatif ainsi que son pouvoir de classification.

-   Evaluation du pouvoir explicatif du modèle

Afin d'évaluer le pouvoir explicatif de notre modèle, on peut calculer son Pseudo-$R^2$. Il en existe plusieurs. Ici, nous allons déterminer celui de McFadden (1973) correspondant au quotient entre la différence des déviances nulles et résiduelles et la déviance nulle.

```{r}
pseudoR2 <- ((glm.best.pa$null.deviance-glm.best.pa$deviance)/glm.best.pa$null.deviance)
pseudoR2
```

D'après ce résultat, on en conclut que notre modèle explique plus de $62.2$% des données. Regardons ensuite si il est capable de bien classer ces données.

-   Evaluation du pouvoir de classification du modèle

Pour évaluer le pouvoir de classification de notre modèle, nous allons juger ses prédictions grâce à une courbe ROC. Afin de ne pas prédire sur des individus ayant servis à la construction du modèle, nous effectuons une validation croisée. En effet, pour chaque individu i, nous estimons le modèle sans cet individu puis nous prédisons la valeur de pa pour celui-ci. Nous obtenons alors les prédictions de pa pour tous les individus et nous pouvons tracer la courbe ROC.

```{r}
pred <- 1:n
for (i in 1:n){
  # On estime le modèle sans i (on l'enlève lorsqu'on estime le modèle)
  fit <- glm(pa~WatrCont + SubsDens + Topo, data=mites, family="binomial", subset=-i)
  # On prédit la proba asscoiée à i
  pred[i] <- predict(fit,mites[i,-2], type="response")
}

pr <- prediction(pred,mites$pa)
roc <- performance(pr, measure="tpr",x.measure="fpr")
plot(roc)
```

Cette courbe résume le taux de vrais positifs en fonction du taux de faux positifs. Elle est d'autant meilleure qu'elle s'éloigne de la diagonale. Ici, nous avons une courbe largement au dessus de la diagonale. Nous pouvons d'ailleurs calculer son aire sous la courbe (AUC).

```{r}
perf <- performance(pr, "auc")
perf@y.values[[1]]
```

L'aire sous la courbe est proche de 1 : le pouvoir prédictif de notre modèle est alors très bon.

Enfin, nous pouvons résumer les bonnes et mauvaises prédictions de notre modèle grâce à une matrice de confusion. Pour cela, il est intéressant de déterminer en amont le seuil à partir duquel on admet la présence de mites. On trace alors la courbe du taux d'erreur en fonction des différents seuils.

```{r}
res.err <- performance(pr,measure = "err")
plot(res.err)
```

Nous remarquons que le taux d'erreur le plus faible est pour un seuil de 0.5. C'est alors le seuil que nous allons choisir pour étblir notre matrice de confusion.

```{r}
table(pred>0.5, mites$pa)
```

D'après cette matrice, nous avons prédit quarante fois l'abscence de mites et vingt-trois fois leur présence en ayant raison. Cependant, le modèle s'est trompé sept fois : cinq fois en ayant prédit l'abscence de mites à tort et deux fois leur présence à tort. Par conséquent, le taux d'erreur est de $\frac{7}{70}=0.1$. On peut en conclure que ce modèle a de bonnes qualités de classification.

Ainsi, nous en déduisons que le modèle expliquant l'occurrence de mites grâce au contenu en eau, à la densité du substrat et à la topographie obtient des bons résultats, tant sur son ajustement que sur son pouvoir de classification.

\newpage

## 3. GLM Régression Logistique sur les données agrégées

**Objectif** : expliquer la fréquence relative `prop`, déterminer le meilleur modèle pour cette variable réponse, interpréter les coefficients, puis évaluer l'ajustement de ce modèle.

La variable `prop` est, comme son nom l'indique, une variable en proportion. Malgré qu'il ne s'agisse pas d'une variable binaire, ce cas est proche d'une régression logistique. En effet, cette fois-ci, au lieu de prédire une valeur binaire échec ou succès (0 ou 1), on veut prédire la proportion de succès $P_i=Y_i/n_i$. Dans notre cas, la valeur $n_i$ est la variable `totalabund` qui représente le nombre total de mites, et la variable $Y_i$ est le nombre de succès, ici le nombre de mites qui sont des Galumna (représenté par la variable `Galumna` elle-même). En clair, nous avons : `prop` = `Galumna/totalabund`. On a $\mathbb{E}(Y_i)=n_i \pi_i$ et donc $\mathbb{E}(P_i)=\pi_i$. Et on modélise les probabilités $\pi_i$ par $g(\pi_i)=x_i^T \beta$ où $x_i$ est le vecteur des variables explicatives, $\beta$ est un vecteur de paramètres et $g$ est la fonction de lien. La fonction de lien pour la régression logistique est la fonction $logit$.

Sous R, on peut utiliser la fonction `glm` de manière semblable à lorsque l'on fait une régression logistique classique, mais en précisant cette fois des poids a priori.

#### 1. Recherche du meilleur modèle

On suivra la même méthode que dans la partie précédente pour chercher le meilleur modèle : une recherche à la main dans un premier temps, puis une méthode de sélection automatique.

-   **Méthode "à la main"**

```{r}
prop.reg.tot <- glm(prop~WatrCont + SubsDens + Topo + Shrub + Substrate, data=mites, family = "binomial", weights = totalabund)
summary(prop.reg.tot)
```

Lorsque l'on effectue le modèle complet, on obtient un warning qui nous dit qu'une ou plusieurs observations du jeu de données sont prédites à 0 ou 1, ce qui ne veut pas forcément dire que la régression logistique est mauvaise. On décide donc d'ignorer le warning. Cependant, on voit qu'il n'y que très peu de variables significatives. On créé un modèle avec les deux variables les plus significatives du modèle complet : `WatrCont` et `SubsDens`.

```{r}
prop.reg.2 <- glm(prop~WatrCont + SubsDens, data=mites, family = "binomial", weights = totalabund)
summary(prop.reg.2)
```

Cette fois-ci on voit que toutes les variables, ainsi que la constante sont significatives pour le test de Wald. Pour rappel, ce test permet de tester la nullité d'un coefficient : $H_0 : \beta_j=0$.

-   **Méthode de sélection automatique**

On effectue maintenant une recherche automatique du meilleur modèle en partant du plus gros modèle et en se basant sur le critère BIC, critère explicatif.

```{r}
prop.reg.back<-step(prop.reg.tot, direction="backward", k=log(nrow(mites)))
prop.reg.back$formula
```

Avec une procédure de sélection backward, on garde 3 variables : `WatrCont`, `SubsDens` et `Topo`.

Pour cette étude, on se place dans un cadre plus explicatif que prédictif. On décide donc de comparer ces trois modèles avec le BIC :

```{r}
kable(data.frame(BIC(prop.reg.tot),BIC(prop.reg.2),BIC(prop.reg.back)), col.names = c("Modèle complet", "Modèle 2 variables", "Modèle 3 variables"), caption = "BIC des différents modèles")
```

Le modèle à trois variables est celui qui minimise le BIC. On peut tout de même effectuer un test de modèle emboîtés afin de regarder si la troisième variable `Topo` est bien significative. On teste donc le modèle à 2 variables contre celui à 3 variables.

```{r}
anova(prop.reg.2, prop.reg.back,test="Chisq")
```

La p-value est inférieure à 0.05 donc la variable `Topo` est significative.

On effectue un summary du modèle à 3 variables.

```{r}
prop.reg.best <- prop.reg.back
summary(prop.reg.best)
```

On remarque que toutes les variables sont significatives d'après le test de Wald.

On retient finalement le modèle suivant :\
$$logit(\hat{prop})=-4.23 -0.006*WatrCont+0.029*SubsDens+0.729*TopoHummock$$

#### 2. Interprétation des coefficients

On peut interpréter les coefficients du modèle pour nos trois variables grâce à leurs odds-ratios. L'odd-ratio pour la variable $j$ est égal à $\exp(\beta_j)$.

```{r}
round(exp(prop.reg.best$coefficients),2)
```

L'odd-ratio pour la variable `WatrCont` est inférieur à 1. De plus, sa p-value associée au test de Wald est inférieure à 5% donc on peut dire que la proportion de mites est significativement moins élevée si la quantité d'eau dans le sol augmente. L'odd-ratio de `SubsDens` est quant à lui supérieur à 1, et sa p-value pour le test de Wald inférieure à 5%. Cela signifie que la proportion de mites sera significativement plus importante si la densité du substrat augmente.\
Enfin, l'odd-ratio pour `Topo` vaut 2.07 et sa p-value est inférieure à 5%. Donc on peut conclure que si la topographie est de type Hummock, la proportion de mites sera significativement plus élevée.

#### 3. Validation du modèle

Enfin, nous devons maintenant regarder si notre modèle est "bon". Nous allons, pour cela, évaluer sa qualité d'ajustement et son pouvoir explicatif.

-   **Evaluation de l'ajustement du modèle**

    -   Effet levier

    On regarde dans un premier temps les points leviers. Ce sont les points qui influencent fortement leur estimation.

    ```{r}
    p<-length(prop.reg.back$coefficients)
    plot(influence(prop.reg.back)$hat, type="h", ylab="h_ii")
    abline(h=c(2*p/n, 3*p/n), col=2)
    ```

    On voit que 5 observations peuvent être déclarées comme "points leviers".

    -   Points influents

    Les points influents sont des points qui influent sur le modèle de telle sorte que si on les enlève, l'estimation des coefficients sera fortement changée. Pour les observer, on représente leur distance de Cook.

    ```{r}
    plot(cooks.distance(prop.reg.back), type="h", ylab="Distance de Cook")
    ```

    On relève plusieurs points influents. Notamment la 8ème observation, qui était déjà un point levier. Généralement, si un point est influent, il est soit levier, soit aberrant, soit les deux.

    -   Analyse des résidus :

    Finalement, nous allons analyser les résidus. On effectue pour cela un *test de Pearson* ou *test global de la qualité de l'ajustement* basé sur les résidus de Pearson. L'hypothèse nulle de ce test est : $H_0 :=$ le modèle ajuste correctement les données.

    ```{r}
    res <- sum(residuals(prop.reg.back, type = "pearson")^2)
    ddl <- n-(p+1)
    pvalue <- 1 - pchisq(res,ddl)
    pchisq(res,ddl)
    ```

    La p-value est très grande. On accepte donc $H_0$ et on conclut que le modèle ajuste correctement les données.

    On finit par représenter les résidus.

    ```{r}
    res<-residuals(prop.reg.back, type="pearson")
    plot(res, ylim=c(-3,5), ylab="Residuals")
    abline(h=c(-2,2), col=2)
    ```

    On voit que les résidus sont répartis de façon homogène autour de l'axe des abscisses. Ils sont pour la plupart proches de 0. Cependant, trois points semblent avoir une valeur de résidu élevée. Peut-être correspondent-ils à des points leviers ou aberrants observés précédemment. Nous pourrions les enlver du jeu de données afin de construire un modèle qui ajusterait encore mieux les données mais nous décidons de les garder car le jeu de données ne contient pas beaucoup d'individus (70) et nous ne voulons pas le réduire davantage. De plus, nous n'avons pas une connaissance très poussée de nos données donc nous ne pourrions pas justifier le retrait de ces individus pour notre étude.

-   **Evaluation du pouvoir explicatif du modèle**

Pour finir la validation du modèle, on calcule le pseudo-$R^2$, qui nous donne la variance expliquée par notre modèle :

```{r}
pseudoR2 <- ((prop.reg.best$null.deviance-prop.reg.best$deviance)/prop.reg.best$null.deviance)
pseudoR2
```

Notre modèle explique $44$% de la variance. Ce score n'est pas très élevé. Cependant, en régression logistique, les valeurs faibles de pseudo-$R^2$ sont souvent courantes.

Ainsi, nous en déduisons que le modèle expliquant la proportion de mites Galumna grâce au contenu en eau, à la densité du substrat et à la topographie obtient de bons résultats.

\newpage

## 4. GLM Régression Poisson sur Abondance (Galumna) :

**Objectif** : modéliser l'abondance de l'espèce Galumna en fonction des caractéristiques du substrat (son contenu en eau `WatrCont` et sa densité `SubsDens`) et, si nécessaire, des autres variables environnementales.

Rappelons que le modèle linéaire général est un cas particulier de GLM, on a : $Y = X\beta + e$ avec $e = (\epsilon_1, \dots, \epsilon_n)^T$ et $\epsilon_i$ sont i.i.d suivant $N(0,\theta^2)$.

Pour une distribution Poisson $y \sim Pois(\lambda)$ avec le lien $log$ par défaut nous avons $log(\lambda)=\eta$ avec l'inverse de ce lien $\lambda=e^\eta$.

Comme pour la régression logistique, la régression de Poisson utilise la fonction `glm`. Il faut spécifier la famille poisson et (optionnellement) le lien $log$. En effet, le logarithme est la foncton de lien par défaut pour la régression de Poisson sur `R`.

#### 1. Recherche du meilleur modèle

-   **Méthode "à la main"**

Nous allons commencer par le modèle complet et ensuite effectuer une sélection de variables

```{r}
glm.tot.poi <- glm(pa~WatrCont + SubsDens + Topo + Shrub + Substrate, data=mites, family = poisson(link='log'))
summary(glm.tot.poi)
```

Nous observons dans le `summary` de notre modèle complet qu'il n'y que très peu de variables significatives. On créé un modèle avec les deux variables significatives du modèle complet : `WatrCont` et `SubsDens`.

```{r}
glm.poi <- glm(Galumna~WatrCont + SubsDens, family = poisson(link = "log"), data = mites )
summary(glm.poi)
```

-   **Recherche automatique**

Avant de confirmer ce modèle, nous allons effectuer une recherche automatique du meilleur modèle en partant du plus gros modèle et en se basant sur le critère BIC, critère explicatif.

```{r}
glm.reg.back<-step(glm.tot.poi, direction="backward", k=log(nrow(mites)))
glm.reg.back$formula
```

Avec une procédure de sélection backward, on garde 3 variables : `WatrCont`, `SubsDens` et `Topo`.

Nous avons donc un nouveau modèle :

```{r}
glm.poi3 <- glm(Galumna~WatrCont + SubsDens + Topo, family = poisson(link = "log"), data = mites )
summary(glm.poi3)
```

Pour cette étude, on se place dans un cadre plus explicatif que prédictif. On décide donc de comparer ces trois modèles avec le BIC :

```{r}
kable(data.frame(BIC(glm.tot.poi),BIC(glm.poi),BIC(glm.poi3)), col.names = c("Modèle 1", "Modèle 2", "Modèle 3"), caption = "BIC des différents modèles")
```

Avec pour le modèle 1, le modèle complet, pour le modèle 2, le modèle avec les variables `WatrCont` et `SubsDens` et le modèle 3, le modèle selectionné par la sélection stepwise.

Le modèle à trois variables est celui qui minimise le BIC. On peut tout de même effectuer un test de modèles emboîtés afin de regarder si la troisième variable `Topo` est bien significative. On teste donc le modèle à 2 variables contre celui à 3 variables.

```{r}
anova(glm.poi3, glm.poi,test="Chisq")
```

La p-value est inférieure à 0.05 donc la variable `Topo` est significative.

```{r}
glm.poi3 <- glm(Galumna~WatrCont + SubsDens + Topo, family = poisson(link = "log"), data = mites )
summary(glm.poi3)
```

De plus, on remarque que toutes les variables sont significatives d'après le test de Wald.

Le modele selectionné s'écrit donc : $$ln(\lambda)=\beta_O+\beta_1*WatrCont+\beta_2*SubsDens+\beta_3*Topo$$ ce qui nous donne à l'aide du `summary` de notre modèle : $$ln(\lambda)=1.89-0.008*WatrCont+0.023*SubsDens + 0.892*Topo $$

#### 2. Interprétation des coefficients

Nous allons maintenant interpréter les coefficients de notre modèle. Nous allons determiner l'effet de chaque coefficient du modèle sur le prédicteur linéaire $\mu_i=\beta_O+\beta_1*WatrCont+\beta_2*SubsDens+\beta_3*Topo$, puis déduire l'effet sur la moyenne de réponse à partir de la fonction $\lambda=e^\eta$.

-   Le coefficient `WatrCont` qui indique le contenu en eau, indique que $\eta$ diminue de 0.008 pour chaque augmentation d'une unité de `WatrCont` si la variable SubsDens reste constante. Nous avons donc le facteur $e^-0.008=0.99$ qui correspond à une perte de 1% de l'abondance de Galumna par unité de contenu en eau (`WatrCont`) supplémentaire.
-   Le coefficient `SubsDens` qui indique la densité, a un changement additif de $0.023$ qui correspond au facteur $e^0.023=1.023267$. On en conclut que la densité n'influe pas sur l'abondance de Galumna.
-   Le coefficient `Topo` qui représente la topographie de type Hummock, a un changement additif de $0.892$ qui correspond au facteur $e^0.892=2.440005$. Cela correspond a une augmentation de 250% de l'abondance de Galumna pour une topographie de type Hummock.

Nous allons maintenant tester si nous avons de la surdispersion dans notre modèle. Par définition, nous avons que quand la déviance résiduelle est supérieur au nombre de degrés résiduels, le modèle est surdispersé. On peut estimer un paramètre de surdispersion $$\phi = \frac{\text{Degré de liberté résiduels}}{\text{Déviance résiduelle}}$$. Nous avons donc $\phi = \frac{91.699}{66}=1.389379$. Sous l'hypothèse nulle de non surdispersion ($\phi=1$), la deviance D suit une loi du $\chi^2$ à $(n-p)=70-4=66$ degrès de liberté. Rappelons que nous rejetons $H_0$ si $D>\chi^2_{66,0.95}$ avec, d'après la table de la loi du khi-deux, $\chi^2_{67,0.95}=85,97$. Dans le `summary` de notre modèle nous avons que $D=91,699$ pour $66$ degrès de liberté. Nous rejetons donc $H_0$ et nous concluons que nous avons de la surdispersion dans nos données. Nous savons que la non-indépendance des observations individuelles peut causer une surdispersion des données par rapport aux suppositions de la distribution de Poisson.

Pour determiner si le $\chi^2$ diffère significativement de la valeur attendue selon la distribution de Poisson, nous pouvons calculer la probabilité d'avoir obtenu un $\chi^2$ plus élevé si le modèle est correct.

```{r}
chisq <- sum((mites$Galumna-fitted(glm.poi3))^2/fitted(glm.poi3))
1-pchisq(chisq, df=glm.poi3$df.residual)
```

```{r}
disp <- chisq/glm.poi3$df.residual
disp
```

L'estimé du paramètre de dispersion est de $\hat{c}=1.9$. Cependant, l'estimation de ce paramètre de dispersion n'est pas trop élevé. Il faut faire attention quand cette valeur dépasse $5$. Les estimés des coefficients de la régression de Poisson demeurent valides, mais il faut multiplier leurs erreurs-types par $\sqrt{\hat{c}}$. Autrement dit, la surdispersion n'introduit pas de biais, mais augmente l'incertitude sur les valeurs des coefficients.

Pour corriger les erreurs-types, nous allons utiliser la famille `quasipoisson` dans notre modèle.

```{r}
glm.poi4 <- glm(Galumna ~ WatrCont + SubsDens + Topo , family = quasipoisson, data = mites )
summary(glm.poi4)
```

Conclure quelque chose ?!

\newpage

# II. Données manquantes

```{r}
set.seed(123)
library(parallel)
library(mvtnorm)
library(stats)
```

## 1. Simulations scénarios NA

### 1.1 Nous allons simuler $n=100$ réalisations d'un vecteur gaussien $(X,Y)$ de moyenne et de variance et ajouter des données manquantes sur Y selon :

```{r}
n <- 100
mu <- c(0,0)
matcov <- matrix(c(1, 0.5, 0.5, 1), nrow=2, ncol = 2)
don <- rmvnorm(n=n, mean = mu, sigma = matcov)
colnames(don) <- c("X", "Y") 
```

#### a. Un mécanisme **MCAR** tel que $P(M=0)=0.35$.

```{r}
set.seed(123)
don.ismcar = don

ismcar <- sample(c(T,F), size = n, prob = c(0.35, 0.65), replace = TRUE)
#Bernouilli trial avec TRUE

don.ismcar[ismcar, "Y"] <- NA
don.ismcar <- as.data.frame(don.ismcar) # création du jeu avec 0.35 de NA pour Y
summary(don.ismcar)
```

#### b. Un mécanisme **MAR** $P(M=0\vert{X})=\mathcal{B}(\phi(1.2X-0.5))$ où $\phi(.)$ désignale la fonction de répartition d'une loi Normale $\mathcal{N}(0,1)$.

```{r}
set.seed(123)

don.ismar <- don
ismar <- sapply(don.ismar[,"X"], FUN=function(xx){
  prob <- pnorm(1.2*xx-.5) #Fonction de rep
  res <- sample(c(T,F), size = 1, prob = c(prob,1-prob))
  return (res)
})

don.ismar[ismar,"Y"] <- NA #Les valeurs de Y tq ismar = T sont mises à NA
don.ismar <- as.data.frame(don.ismar)
don.ismar
summary(don.ismar)
```

#### c. Un mécanisme **MNAR** $P(M=0\vert{Y})=\mathcal{B}(\phi(1.2X-0.5))$.

```{r}
set.seed(123)

don.ismnar <- don
ismnar <- sapply(don.ismnar[,"Y"], FUN=function(xx){
  prob <- pnorm(1.2*xx-.5) #Fonction de rep
  res <- sample(c(T,F), size = 1, prob = c(prob,1-prob))
  return (res)
})

don.ismnar[ismnar,"Y"] <- NA #Les valeurs de Y tq ismar = T sont mises à NA
don.ismnar <- as.data.frame(don.ismnar)
don.ismnar
summary(don.ismnar)
```

### 1.2. " Analyser les avec les outils de description évoqués précédemment"
